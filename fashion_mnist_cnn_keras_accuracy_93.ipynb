{
  "cells": [
    {
      "metadata": {
        "_uuid": "10407b70d0d53cb20a50a8bba98c714d303a3796",
        "id": "ljY4nxR1B92H"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion-MNIST\n",
        "1) Fashion-MNIST is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples.\n",
        "\n",
        "2) Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "3) Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms.\n",
        "\n",
        "4) It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "* **You can also view the notebook and contribute below.**\n",
        "* **Github Link ->** [**Fashion-MNIST**](https://github.com/Chinmayrane16/Fashion-MNIST-Accuracy-93.4-)\n",
        "* **Do Star/Upvote if you like it ;)**\n",
        "\n",
        "\n",
        "* **If you need more Detailed explanations on the various terminologies used here, **\n",
        "* **you can refer to my kernel -> **[**Beginners Guide to CNN (MNIST)**](https://www.kaggle.com/fuzzywizard/beginners-guide-to-cnn-accuracy-99-7)"
      ]
    },
    {
      "metadata": {
        "_uuid": "5e3bb0162ebea5b832d4d7416b453c514cdbc58a",
        "id": "dzuTXQFIB92L"
      },
      "cell_type": "markdown",
      "source": [
        "## Topics\n",
        "1. [**Exploring the Dataset**](#there_you_go_1)\n",
        "> *  [1.1 Importing Libraries ](#there_you_go_1.1)\n",
        "  * [1.2 Extract dataset ](#there_you_go_1.2)\n",
        "  * [1.3 Features ](#there_you_go_1.3)\n",
        "  * [1.4 Examine Dimensions ](#there_you_go_1.4)\n",
        "  * [1.5 Examine NaN values ](#there_you_go_1.5)\n",
        "2. [**Visualizing the Dataset**](#there_you_go_2)\n",
        "> * [2.1 Plotting Random Images ](#there_you_go_2.1)\n",
        "  * [2.2 Distribution of Labels ](#there_you_go_2.2)\n",
        "3. [**Data PreProcessing**](#there_you_go_3)\n",
        "> * [3.1 Setting Random Seeds ](#there_you_go_3.1)\n",
        " * [3.2 Splitting Data ](#there_you_go_3.2)\n",
        " * [3.3 Reshaping Images ](#there_you_go_3.3)\n",
        " * [3.4 Normalization ](#there_you_go_3.4)\n",
        " * [3.5 One Hot Encoding ](#there_you_go_3.5)\n",
        "4. [**Training ConvNet**](#there_you_go_4)\n",
        "> * [4.1 Building a ConvNet ](#there_you_go_4.1)\n",
        " * [4.2 Compiling Model ](#there_you_go_4.2)\n",
        " * [4.3 Model Summary ](#there_you_go_4.3)\n",
        " * [4.4 Learning Rate Decay ](#there_you_go_4.4)\n",
        " * [4.5 Data Augmentation ](#there_you_go_4.5)\n",
        " * [4.6 Fitting the Model](#there_you_go_4.6)\n",
        "5. [**Evaluating the Model**](#there_you_go_5)\n",
        "> * [5.1 Plotting Train and Validation curves ](#there_you_go_5.1)\n",
        "6. [**Plotting Confusion Matrix**](#there_you_go_6)\n",
        "7. [**Visualization of Predicted Classes**](#there_you_go_7)\n",
        "> * [7.1 Correctly Predicted Classes](#there_you_go_7.1)\n",
        " * [7.2 Incorrectly Predicted Classes](#there_you_go_7.2)\n",
        "8. [**Classification Report**](#there_you_go_8)\n",
        "9. [**Predicting on Test Data**](#there_you_go_9)"
      ]
    },
    {
      "metadata": {
        "_uuid": "42cae3e5622e4f298b797c8b55d565640d2c8953",
        "id": "NAy1n8XGB92O"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_1\"></a>\n",
        "# 1) Exploring The Dataset"
      ]
    },
    {
      "metadata": {
        "_uuid": "cb6ff7f603887ceb066adbfb79e0015f80cb7d58",
        "id": "9PcPQ6AXB92P"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_1.1\"></a>\n",
        "## 1.1) Importing Libraries"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "eLGVQIGcB92P"
      },
      "cell_type": "code",
      "source": [
        "# Ignore warnings :\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Handle table-like data and matrices :\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import itertools\n",
        "\n",
        "\n",
        "\n",
        "# Modelling Algorithms :\n",
        "\n",
        "# Classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\n",
        "\n",
        "# Regression\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Modelling Helpers :\n",
        "from sklearn.preprocessing import Normalizer , scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#evaluation metrics :\n",
        "\n",
        "# Regression\n",
        "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error\n",
        "\n",
        "# Classification\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "\n",
        "\n",
        "# Deep Learning Libraries\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "\n",
        "# Configure visualisations\n",
        "%matplotlib inline\n",
        "mpl.style.use( 'ggplot' )\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b22ccc48eb3a048895b260e4b54273cb2b8aff9d",
        "trusted": true,
        "id": "fAR4pmXdB92S"
      },
      "cell_type": "code",
      "source": [
        "# Center all plots\n",
        "from IPython.core.display import HTML\n",
        "HTML(\"\"\"\n",
        "<style>\n",
        ".output_png {\n",
        "    display: table-cell;\n",
        "    text-align: center;\n",
        "    vertical-align: middle;\n",
        "}\n",
        "</style>\n",
        "\"\"\");\n",
        "\n",
        "# Make Visualizations better\n",
        "params = {\n",
        "    'axes.labelsize': \"large\",\n",
        "    'xtick.labelsize': 'x-large',\n",
        "    'legend.fontsize': 20,\n",
        "    'figure.dpi': 150,\n",
        "    'figure.figsize': [25, 7]\n",
        "}\n",
        "plt.rcParams.update(params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22aa2082359a7304e2cd4798bc155d5dc23b2b42",
        "id": "71Ll368yB92T"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_1.2\"></a>\n",
        "## 1.2) Extract Dataset"
      ]
    },
    {
      "metadata": {
        "_uuid": "67db5f0b861cd539953ce067e7653cb2b202a56a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TYktaxWB92U",
        "outputId": "91c52336-baf2-4a9b-c422-4ce6c35b466d"
      },
      "cell_type": "code",
      "source": [
        "!pip install emnist\n",
        "\n",
        "\n",
        "from emnist import extract_training_samples\n",
        "images, labels = extract_training_samples('letters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emnist\n",
            "  Downloading emnist-0.0-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from emnist) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from emnist) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from emnist) (4.65.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->emnist) (2023.7.22)\n",
            "Installing collected packages: emnist\n",
            "Successfully installed emnist-0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading emnist.zip: 536MB [00:17, 32.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b7de78369a7a7cbf49844a9e38cf2af20b3c5d57",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4nTCmgRB92V",
        "outputId": "c9947672-4105-4b4b-b367-3b54fc0b5de7"
      },
      "cell_type": "code",
      "source": [
        "images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SymgjfryCdUr",
        "outputId": "755b3f88-f390-432f-cbee-0742cf98cec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23,  7, 16, ..., 13, 15, 19], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert it into DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "from emnist import extract_training_samples\n",
        "\n",
        "images, labels = extract_training_samples('letters')\n",
        "images_flat = images.reshape(images.shape[0], -1)\n",
        "data = {'images': images_flat.tolist(), 'labels': labels.tolist()}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SMWordPECdRm",
        "outputId": "f4d584f2-d445-4ee5-a939-afc8c05ea6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              images  labels\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      23\n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       7\n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      16\n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      15\n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      23"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-9217daf9-2c2f-4e2a-8332-a5a49db9ea74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9217daf9-2c2f-4e2a-8332-a5a49db9ea74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-232298b2-baf9-4141-95d8-189ee109ee67\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-232298b2-baf9-4141-95d8-189ee109ee67')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-232298b2-baf9-4141-95d8-189ee109ee67 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9217daf9-2c2f-4e2a-8332-a5a49db9ea74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9217daf9-2c2f-4e2a-8332-a5a49db9ea74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = df['labels'].nunique()\n",
        "print(\"Number of classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LMRsODCCdO7",
        "outputId": "b4298d3d-32d7-4176-dea1-8f0eff7c0c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EBKfYRmCdMJ",
        "outputId": "b683843c-7c61-458b-81d9-5a8abea85e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 124800 entries, 0 to 124799\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   images  124800 non-null  object\n",
            " 1   labels  124800 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8VAH1m-CdJd",
        "outputId": "218ec7d7-4f11-4d7f-8ca1-cbad32da7293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                                                    images  labels\n",
              "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      23\n",
              "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       7\n",
              "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      16\n",
              "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      15\n",
              "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      23\n",
              "...                                                   ...     ...\n",
              "124795  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       2\n",
              "124796  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      18\n",
              "124797  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      13\n",
              "124798  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      15\n",
              "124799  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      19\n",
              "\n",
              "[124800 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1wkJhZSFoCM",
        "outputId": "7ec4a9f8-4be0-4a93-bde9-e1b4591bb6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23    4800\n",
              "7     4800\n",
              "20    4800\n",
              "3     4800\n",
              "4     4800\n",
              "8     4800\n",
              "1     4800\n",
              "12    4800\n",
              "9     4800\n",
              "25    4800\n",
              "2     4800\n",
              "5     4800\n",
              "19    4800\n",
              "26    4800\n",
              "21    4800\n",
              "18    4800\n",
              "14    4800\n",
              "10    4800\n",
              "24    4800\n",
              "22    4800\n",
              "11    4800\n",
              "13    4800\n",
              "17    4800\n",
              "15    4800\n",
              "16    4800\n",
              "6     4800\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = images / 255.0\n",
        "\n",
        "images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
        "print(\"Reshaped images shape:\", images.shape)\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(\"X_train shape:\", X_train.shape)\n",
        "# print(\"X_val shape:\", X_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxCWB3xjDwRU",
        "outputId": "fc18d8ec-e3b8-4426-9f11-5f88396ce152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped images shape: (124800, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['images'].tolist()\n",
        "y = df['labels'].tolist()"
      ],
      "metadata": {
        "id": "oG5KsoHYDD2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", len(X_train))\n",
        "print(\"X_test shape:\", len(X_test))\n",
        "print(\"y_train shape:\", len(y_train))\n",
        "print(\"y_test shape:\", len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XC0E9ApDD6B",
        "outputId": "bd45eb32-626f-40f0-c6bb-c6ccd6f43cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: 99840\n",
            "X_test shape: 24960\n",
            "y_train shape: 99840\n",
            "y_test shape: 24960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "YvjmbFfSDD9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "i7qOtV7PDM5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "df.isnull().any().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcboCzYqDoP-",
        "outputId": "0e520a57-0860-415a-f912-fa5d5d5c4b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lUndnpDuDoMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NWQBSWSyDoKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQiXKmxhDoIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "815dDPlZDoHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMWrcmPhDoFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g47GFnyFDn2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2691bf7440abbcdef95e7ba31048d9e5a265530b",
        "id": "0rsDYSkUB92W"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_1.3\"></a>\n",
        "## 1.3) Features\n",
        "* **Label: ** The Target variable.\n",
        "* **Pixels: ** The smallest unit of a Digital Image or Graphic that can be displayed on Digital Display Device.\n",
        "\n",
        "Where humans can see the objects due to the Light Receptors in their Eyes which send Signals via the Optic Nerve to the Primary Visual Cortex, where the input is processed ,\n",
        "\n",
        "Computers on the other hand, see the Image as 2-dimensional arrays of numbers, known as pixels. They Classify Images based on Boundaries and Curvatures of the Object (Represented by pixel values, either RGB or GrayScale) .\n",
        "\n",
        "This is the Partial View of the Labels and the Dataset."
      ]
    },
    {
      "metadata": {
        "_uuid": "f914af34422ae0dae8e776b517727f57a1dc4d18",
        "id": "sJjswJDxB92W"
      },
      "cell_type": "markdown",
      "source": [
        "![Imgur](https://i.imgur.com/coDqChv.png)"
      ]
    },
    {
      "metadata": {
        "_uuid": "8c53daa7e38fedfbf4084ccd89a84435f5f1a526",
        "collapsed": true,
        "id": "EM8ZvcnkB92X"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_1.4\"></a>\n",
        "## 1.4) Examine Dimensions"
      ]
    },
    {
      "metadata": {
        "_uuid": "04c3e2df1d86c90322387a5303e1283ac64c2355",
        "trusted": true,
        "id": "hDj0uzDJB92X"
      },
      "cell_type": "code",
      "source": [
        "print('Train: ', df.shape)\n",
        "print('Test: ', df_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "80767f17f45a6de0bfeadf84018d8b97ac93faab",
        "id": "J2wWOTS-B92Y"
      },
      "cell_type": "markdown",
      "source": [
        "* **So, there are 60,000 Training Samples and 10,000 Test Samples.**\n",
        "* **Each example is a 28x28 grayscale image, associated with a label from 10 classes.**\n",
        "> * Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker.\n",
        "> * This pixel-value is an integer between 0 and 255, inclusive.\n",
        "* **The first column of the Training Samples consists of Class Labels and represents the article of Clothing.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "446239c44659c9eeceb70696f33d76dc352658e9",
        "scrolled": true,
        "trusted": true,
        "id": "YyU18h2QB92Y"
      },
      "cell_type": "code",
      "source": [
        "df.label.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "da6c5f37e32d18e055f92b32d708507c568e6a04",
        "id": "70AW_oKIB92Y"
      },
      "cell_type": "markdown",
      "source": [
        "**Labels :**\n",
        "* **0 - ** T-shirt/top\n",
        "* **1 - ** Trouser\n",
        "* **2 - ** Pullover\n",
        "* **3 - ** Dress\n",
        "* **4 - ** Coat\n",
        "* **5 - ** Sandals\n",
        "* **6 - ** Shirt\n",
        "* **7 - ** Sneaker\n",
        "* **8 - ** Bag\n",
        "* **9 - ** Ankle Boots"
      ]
    },
    {
      "metadata": {
        "_uuid": "68e164f2d414f5f6da3070cfa1769477ba099d70",
        "id": "Xj_g2zlPB92Z"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_1.5\"></a>\n",
        "## 1.5) Examine NaN Values"
      ]
    },
    {
      "metadata": {
        "_uuid": "0fc53f65d39dad92d21e1fb53cdaad71bad43f60",
        "trusted": true,
        "id": "m5xat3VSB92Z"
      },
      "cell_type": "code",
      "source": [
        "# Train\n",
        "df.isnull().any().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7a07c42581ca81b64e30b76c61e0f3be8f36bc2b",
        "trusted": true,
        "id": "3eqCPPRDB92Z"
      },
      "cell_type": "code",
      "source": [
        "# Test\n",
        "df_test.isnull().any().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "96e29d64d3abfecea48b8b164f8930703ddaac53",
        "id": "Kg9ijBS3B92a"
      },
      "cell_type": "markdown",
      "source": [
        "**Great, So there are No Null Values in Train and Test Set.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "f35ffca43e43f762ac55f3d8c8617520714fad58",
        "id": "NbVeQf3kB92a"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_2\"></a>\n",
        "# 2) Visualizing the Dataset"
      ]
    },
    {
      "metadata": {
        "_uuid": "4228bc94d924c8a8df845e8b0b82198e0eacb6fa",
        "id": "PGuNbu4lB92a"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_2.1\"></a>\n",
        "## 2.1) Plotting Random Images"
      ]
    },
    {
      "metadata": {
        "_uuid": "065b300923e239b2c7deff1406e3035f4f67a163",
        "trusted": true,
        "id": "zLfDGxY-B92b"
      },
      "cell_type": "code",
      "source": [
        "# Mapping Classes\n",
        "clothing = {0 : 'T-shirt/top',\n",
        "            1 : 'Trouser',\n",
        "            2 : 'Pullover',\n",
        "            3 : 'Dress',\n",
        "            4 : 'Coat',\n",
        "            5 : 'Sandal',\n",
        "            6 : 'Shirt',\n",
        "            7 : 'Sneaker',\n",
        "            8 : 'Bag',\n",
        "            9 : 'Ankle boot'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9a9b77808e43c9b73543932939a70a458cafb441",
        "trusted": true,
        "id": "ye_TCks8B92c"
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(4, 4, figsize = (15,15))\n",
        "for row in axes:\n",
        "    for axe in row:\n",
        "        index = np.random.randint(60000)\n",
        "        img = df.drop('label', axis=1).values[index].reshape(28,28)\n",
        "        cloths = df['label'][index]\n",
        "        axe.imshow(img, cmap='gray')\n",
        "        axe.set_title(clothing[cloths])\n",
        "        axe.set_axis_off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1cc31daac22d3cc03cae1040ebda50e9d2ff5743",
        "id": "nGGZ6stHB92d"
      },
      "cell_type": "markdown",
      "source": [
        "**Look at these Images, I bet, there will be images which even the Humans won't be able to claasify.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "dce1f7c727dc74a9d44e6c82911a1114d2049f9a",
        "id": "tud1_xeGB92d"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_2.2\"></a>\n",
        "## 2.2) Distribution of Labels\n",
        "**Let's look at the Distribution of labels to anaylze if there are any skewed classes.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "4f4f3d3c472d68a0e2c20f57445d6caa06ea425c",
        "trusted": false,
        "id": "E4Sayl7bB92e"
      },
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d2c68fc20b422e65043b7a35afebb2173fc1e499",
        "trusted": false,
        "id": "cwn6Mt11B92e"
      },
      "cell_type": "code",
      "source": [
        "sns.factorplot(x='label', data=df, kind='count', size=3, aspect= 1.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b8a6f61626b6e922aceeb060081673c4bd001211",
        "id": "JYyiXMuFB92f"
      },
      "cell_type": "markdown",
      "source": [
        "* **We can see that all classes are equally Distributed.**\n",
        "* **So, there is no need for OverSampling or UnderSampling.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "45dfc56342ce479e05f02ad0b429fd92d578d32a",
        "id": "7EXc4GZ4B92f"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_3\"></a>\n",
        "# 3) Data PreProcessing"
      ]
    },
    {
      "metadata": {
        "_uuid": "639f3ed5dedb8535e4e92c40bc0bda007cc2eb72",
        "id": "EdUX6dpuB92g"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_3.1\"></a>\n",
        "## 3.1) Setting Random Seeds"
      ]
    },
    {
      "metadata": {
        "_uuid": "a240ec84ebfcfd7e024941b7f712ae4e04d48914",
        "trusted": false,
        "id": "w_WcPya2B92g"
      },
      "cell_type": "code",
      "source": [
        "# Setting Random Seeds for Reproducibilty.\n",
        "seed = 66\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1aec66be014ad0ce44c6dcf1ec830790b176633a",
        "id": "tjiHZWv7B92g"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_3.2\"></a>\n",
        "## 3.2) Splitting Data into Train and Validation Set\n",
        "Now we are gonna split the training data into Train and Validation Set. Train set is used for Training the model and Validation set is used for Evaluating our Model's Performance on the Dataset.\n",
        "\n",
        "This is achieved using the train_test_split method of scikit learn library."
      ]
    },
    {
      "metadata": {
        "_uuid": "297527ed66f5660c742803d0b75e59c2ce5da3db",
        "trusted": false,
        "id": "W2k_1kuXB92h"
      },
      "cell_type": "code",
      "source": [
        "X = train.iloc[:,1:]\n",
        "Y = train.iloc[:,0]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "679797f1093b9516b65d8b3664ac86de4c2d61c5",
        "id": "Ed3AyfW2B92h"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_3.3\"></a>\n",
        "## 3.3) Reshaping the Images\n",
        "* Note that we have Images as 1D vector each containing 784 pixels. Before we feed the data to the CNN we must reshape the data into (28x28x1) 3D matrices.\n",
        "* This is because Keras wants an Extra Dimension in the end, for channels. If this had been RGB images, there would have been 3 channels, but as MNIST is gray scale it only uses one."
      ]
    },
    {
      "metadata": {
        "_uuid": "44e7fe30d346829486385e0dfb67ce2ac4ced14e",
        "trusted": false,
        "id": "6oW60feBB92h"
      },
      "cell_type": "code",
      "source": [
        "# The first parameter in reshape indicates the number of examples.\n",
        "# We pass it as -1, which means that it is an unknown dimension and we want numpy to figure it out.\n",
        "\n",
        "# reshape(examples, height, width, channels)\n",
        "x_train = x_train.values.reshape((-1, 28, 28, 1))\n",
        "x_test = x_test.values.reshape((-1, 28, 28, 1))\n",
        "\n",
        "df_test.drop('label', axis=1, inplace=True)\n",
        "df_test = df_test.values.reshape((-1, 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b6dfe56d11225f708797f62b81763a423e0f8af",
        "collapsed": true,
        "id": "P5hu1T3gB92i"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_3.4\"></a>\n",
        "## 3.4) Normalization\n",
        "The Pixel Values are often stored as __*Integer*__ Numbers in the range 0 to 255, the range that a single 8-bit byte can offer.\n",
        "They need to be scaled down to [0,1] in order for Optimization Algorithms to work much faster. Here, we acheive Zero Mean and Unit Variance.\n",
        "\n",
        "Normalization is carried out as follows:\n",
        "> x = (x - min) / (max - min) ; Here min=0 and max=255"
      ]
    },
    {
      "metadata": {
        "_uuid": "997b7aeccc979ea590a4e86a512f26fae62409a7",
        "collapsed": true,
        "id": "pBEUScemB92i"
      },
      "cell_type": "markdown",
      "source": [
        "![Imgur](https://i.imgur.com/CFlSx1M.jpg)"
      ]
    },
    {
      "metadata": {
        "_uuid": "6c7bf66bf35c954be77ed21ae29fb60cc662b844",
        "trusted": false,
        "id": "6_bixGQ3B92i"
      },
      "cell_type": "code",
      "source": [
        "# You need to make sure that your Image is cast into double/float from int before you do this scaling\n",
        "# as you will most likely generate floating point numbers.\n",
        "# And had it been int, the values will be truncated to zero.\n",
        "\n",
        "x_train = x_train.astype(\"float32\")/255\n",
        "x_test = x_test.astype(\"float32\")/255\n",
        "df_test = df_test.astype(\"float32\")/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "595bbfa9f59d8b9766b10f762d40235dd8b30096",
        "id": "heFFzVk7B92t"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_3.5\"></a>\n",
        "## 3.5) One Hot Encoding\n",
        "The labels are given as integers between 0-9. We need to one hot encode them , Eg 8 [0, 0, 0, 0, 0, 0, 0, 0, 1, 0] .\n",
        "\n",
        "We have 10 digits [0-9] or classes, therefore we one-hot-encode the target variable with 10 classes"
      ]
    },
    {
      "metadata": {
        "_uuid": "c094b12077df5b889a829a8330b9a0164fb7e3d3",
        "trusted": false,
        "id": "JqBANheNB92u"
      },
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d80addf0198addf15fde1f2718b8ef3179895a93",
        "trusted": false,
        "id": "2gaWOqQiB92u"
      },
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1d983be26ec8c1876137e47deb893e2280c303c6",
        "id": "sS5RoBZEB92v"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_4\"></a>\n",
        "# 4) Training a Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "_uuid": "ebc2b1a5b0777929f0576e7c6f8f9d92332d4bd4",
        "id": "mrZ_Ps5nB92w"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_4.1\"></a>\n",
        "## 4.1) Building a ConvNet"
      ]
    },
    {
      "metadata": {
        "_uuid": "8c0fba030238d3fedeaf204c5b5503e70420350a",
        "id": "HIkN_knHB92w"
      },
      "cell_type": "markdown",
      "source": [
        "* Steps:\n",
        "\n",
        "1) At First, we use **Sequential Keras API** which is just a linear stack of layers. We add one layer at a time starting from input.\n",
        "\n",
        "2) Next We add **Convolutional Layers**, which are the Building blocks of ConvNets. Convolutional Layers has set of Independent Filters whose depth is equal to Input and other dimensions can be set manually. These Filters when convolved over the Input Image produce Feature Maps.\n",
        "\n",
        "It includes some HyperParameters such as **The number of filters, Dimensions of Filter (F), Stride (S), Padding(P) , Activation Function etc. which we input manually. Let the Input Volume Size be deonted by (W) ,**\n",
        "\n",
        "**Then, the Output will have Dimensions given by -->**\n",
        "\n",
        "**(Height, Width) = ( ( W − F + 2P ) / S ) + 1**\n",
        "\n",
        "And the Depth will be equal to Number of Filters Specified.\n",
        "\n",
        "3) Next We add **Pooling Layers**, which are used for Dimensionality Reduction or DownSampling the Input. These are used where we have lot of Input Features. It reduces the amount of Parameters and Computational power required drastically, thus reducing Overfitting. These along with Convolutional layers are able to learn more Complex features of the Image.\n",
        "\n",
        "4) We add **Batch Normalization** where we acheive Zero mean and Variance one. It scales down outliers and forces the network to learn features in a distributed way, not relying too much on a Particular Weight and makes the model better Generalize the Images.\n",
        "\n",
        "5) To avoid Overfitting We add **Dropout**. This randomly drops some percentage of neurons, and thus the weights gets Re-Aligned. The remaining Neurons learn more features and this reduces the dependency on any one Neuron. DropOut is a Regularization Technique, which Penalizes the Parameters. Generally we set the DropOutRate between 0.2-0.5 .\n",
        "\n",
        "6) Finally we add **Flatten layer** to map the input to a 1D vector. We then add Fully connected Layers after some convolutional/pooling layers. It combines all the Features of the Previous Layers.\n",
        "\n",
        "7) Lastly, we add the **Output Layer**. It has units equal to the number of classes to be identified. Here, we use 'sigmoid' function if it is Binary Classification otherwise 'softmax' activation function in case of Multi-Class Classification."
      ]
    },
    {
      "metadata": {
        "_uuid": "e1bd5d99b665d9fbd3e2018a17a9646ce03f2aba",
        "trusted": false,
        "id": "WfuZlJj0B92x"
      },
      "cell_type": "code",
      "source": [
        "# Building a ConvNet\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same',\n",
        "                 data_format='channels_last', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', strides=1, padding='same',\n",
        "                 data_format='channels_last'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', strides=1, padding='same',\n",
        "                 data_format='channels_last'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', strides=1, padding='same',\n",
        "                 data_format='channels_last'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f639c9d5e4362e21ea8119b58d877ba926ad09f2",
        "id": "c0obRfYwB92x"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_4.2\"></a>\n",
        "## 4.2) Compiling the Model\n",
        "1) We need to compile the model. We have to specify the optimizer used by the model We have many choices like Adam, RMSprop etc.. Refer to Keras doc for a comprehensive list of the optimizers available.\n",
        "\n",
        "2) Next we need to specify the loss function for the neural network which we want to minimize.\n",
        "\n",
        "For Binary Classification we use \"binary_crossentropy\" and for Multi-class Classification we use \"categorical_crossentropy\".\n",
        "\n",
        "3) Finally,  We need to specify the metric to evaluate our models performance. Here I have used accuracy."
      ]
    },
    {
      "metadata": {
        "_uuid": "3623f1c509763029ae18fe9ba17027fdc686e3a6",
        "trusted": false,
        "id": "MZXbN7a4B92y"
      },
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "70c1cc49d1a0236cbaf0c09b15d923962cbb2d67",
        "trusted": false,
        "id": "zRL-XQGvB92y"
      },
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ea1936bbfe0ba63afd9730e426f51708b5818dd5",
        "id": "9414Rg2jB92z"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_4.3\"></a>\n",
        "## 4.3) Model Summary"
      ]
    },
    {
      "metadata": {
        "_uuid": "609daae606f5f04702059e28eb380a13ece039d8",
        "trusted": false,
        "id": "ko2UNkJOB92z"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b932f32e4e9ba7cc425290320ebbc31f3807b186",
        "id": "ZAB1AzqSB92z"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_4.4\"></a>\n",
        "## 4.4) Learning Rate Decay\n",
        "* The Learning rate should be properly tuned , such that it is not too high to take very large steps, neither it should be too small , which would not alter the Weights and Biases.\n",
        "* We will use **LearningRateScheduler** here, which takes the step decay function as argument and return the updated learning rates for use in optimzer at every epoch stage. Basically it outputs a new learning rate at every epoch stage."
      ]
    },
    {
      "metadata": {
        "_uuid": "d6916453964d5d335d80f721763435df091b63ba",
        "trusted": false,
        "id": "6PWZ66nKB920"
      },
      "cell_type": "code",
      "source": [
        "reduce_lr = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cc3efdec2bfa8b3e4983d20f0b9df3f38791ee73",
        "id": "DX-3Ex54B920"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_4.5\"></a>\n",
        "## 4.5) Data Augmentation"
      ]
    },
    {
      "metadata": {
        "_uuid": "a1d1a2108e36087e0448b3d626880d64c5504eab",
        "trusted": false,
        "id": "zqqLCH0MB920"
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        rotation_range = 8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image\n",
        "        shear_range = 0.3,# shear angle in counter-clockwise direction in degrees\n",
        "        width_shift_range=0.08,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.08,  # randomly shift images vertically (fraction of total height)\n",
        "        vertical_flip=True)  # randomly flip images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "234ebf5c7adb3478d23de2908088679300cbcf37",
        "trusted": false,
        "id": "YcILAS6fB921"
      },
      "cell_type": "code",
      "source": [
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "44e636df93f455c2586a64dddb87d6db20e57892",
        "id": "GGrvq5O9B921"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_4.6\"></a>\n",
        "## 4.6) Fitting the Model"
      ]
    },
    {
      "metadata": {
        "_uuid": "9c7b841493ef99398738f589096dd2d648d5e9a6",
        "trusted": false,
        "id": "bxP36RxQB922"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a5adc17fd73d4a769b1d270f1c5bcdc8579acb0e",
        "trusted": false,
        "id": "8N0x7QrVB922"
      },
      "cell_type": "code",
      "source": [
        "# Fit the Model\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size = batch_size), epochs = epochs,\n",
        "                              validation_data = (x_test, y_test), verbose=2,\n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              callbacks = [reduce_lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8aab8dba9d00a36dd45e9ec701f9f1af99f1e78c",
        "collapsed": true,
        "id": "d_67pNfVB922"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_5\"></a>\n",
        "# 5) Evaluating the Model"
      ]
    },
    {
      "metadata": {
        "_uuid": "b0362564ce45935a9c3bfc4042e92c5c9359347f",
        "trusted": false,
        "id": "wBx1PZwmB923"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Loss: {:.4f}'.format(score[0]))\n",
        "print('Accuracy: {:.4f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "99f9811e7aa665e784e61263c963e528e9ce36b4",
        "id": "XQFP1qbKB923"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_5.1\"></a>\n",
        "## 5.1) Plotting the Training and Validation Curves"
      ]
    },
    {
      "metadata": {
        "_uuid": "627f94782eec1aff578f09e40a4e5baf9666f7f3",
        "trusted": false,
        "id": "Jw9Pol5LB924"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title(\"Model Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "477ee126d00fdef18c4126025d95c83b73111d25",
        "scrolled": true,
        "trusted": false,
        "id": "lFpnRgCMB924"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Test'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "23f52f557052f6479d74b5002740ea9d2988e962",
        "id": "XZ9ruMsxB925"
      },
      "cell_type": "markdown",
      "source": [
        "**The Training and Validation Curves being close, we can conclude that the Model is not Overfitting the Data.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "4d51f8dfa45a201cc73d3b6a96b65facce32af5e",
        "id": "75Ujv2qOB925"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_6\"></a>\n",
        "# 6) Confusion Matrix\n",
        "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
        "\n",
        "Let's view the the Performance of our classification model on the data using Confusion Matrix."
      ]
    },
    {
      "metadata": {
        "_uuid": "21d1d70e8633b94ceffdead790dedb247f4f5ddb",
        "trusted": false,
        "id": "TxnoYal_B925"
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8b2461d6f3b695364ba871507b5f6ad9bc9a90cc",
        "trusted": false,
        "id": "so6NsnNTB926"
      },
      "cell_type": "code",
      "source": [
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(x_test)\n",
        "# Convert predictions classes to one hot vectors\n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1)\n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(y_test,axis = 1)\n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx,\n",
        "            classes = ['T-shirt/Top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2a331af3526f6489d3b59856660e87ff2c2c35a4",
        "id": "tuQMjuWwB926"
      },
      "cell_type": "markdown",
      "source": [
        "* **We can see that a large number of T-shirt  are misclassified as Shirt.**\n",
        "* **Followed by, Shirts wrongly classified as Coat.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "56fc8be1b533412734a21121045add1b3aff34f9",
        "collapsed": true,
        "id": "JVdneB_bB927"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_7\"></a>\n",
        "# 7) Visualization of Predicted Classes"
      ]
    },
    {
      "metadata": {
        "_uuid": "f735255b88af6e56806f9679b268d96594ea830b",
        "id": "xp9hrAbLB927"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_7.1\"></a>\n",
        "## 7.1) Correctly Predicted Classes"
      ]
    },
    {
      "metadata": {
        "_uuid": "8dc89b8c0ccf28930c77b248603ca114d1936540",
        "trusted": false,
        "id": "ckXyHy_oB927"
      },
      "cell_type": "code",
      "source": [
        "correct = []\n",
        "for i in range(len(y_test)):\n",
        "    if(Y_pred_classes[i] == Y_true[i]):\n",
        "        correct.append(i)\n",
        "    if(len(correct) == 4):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bb278878d6ed8c1109cc3e946ccfa9e7d9de5062",
        "trusted": false,
        "id": "Lgh-UEguB928"
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2,2, figsize=(12,6))\n",
        "fig.set_size_inches(10,10)\n",
        "ax[0,0].imshow(x_test[correct[0]].reshape(28,28), cmap='gray')\n",
        "ax[0,0].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[correct[0]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[correct[0]]]))\n",
        "ax[0,1].imshow(x_test[correct[1]].reshape(28,28), cmap='gray')\n",
        "ax[0,1].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[correct[1]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[correct[1]]]))\n",
        "ax[1,0].imshow(x_test[correct[2]].reshape(28,28), cmap='gray')\n",
        "ax[1,0].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[correct[2]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[correct[2]]]))\n",
        "ax[1,1].imshow(x_test[correct[3]].reshape(28,28), cmap='gray')\n",
        "ax[1,1].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[correct[3]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[correct[3]]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f89af13e3bd8e19f21f3397ad8a7ff4abb5b1874",
        "id": "vksqxm9dB928"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_7.2\"></a>\n",
        "## 7.2) Incorrectly Predicted Classes"
      ]
    },
    {
      "metadata": {
        "_uuid": "096ae7975e2fc37c1d60660e78f232b9b7e9a2c2",
        "trusted": false,
        "id": "bUBwm1pZB928"
      },
      "cell_type": "code",
      "source": [
        "incorrect = []\n",
        "for i in range(len(y_test)):\n",
        "    if(not Y_pred_classes[i] == Y_true[i]):\n",
        "        incorrect.append(i)\n",
        "    if(len(incorrect) == 4):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0ab8c32c6c66885eb2c07cf49bbbda2a60d7f91c",
        "trusted": false,
        "id": "NwrvgvPbB929"
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2,2, figsize=(12,6))\n",
        "fig.set_size_inches(10,10)\n",
        "ax[0,0].imshow(x_test[incorrect[0]].reshape(28,28), cmap='gray')\n",
        "ax[0,0].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[incorrect[0]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[incorrect[0]]]))\n",
        "ax[0,1].imshow(x_test[incorrect[1]].reshape(28,28), cmap='gray')\n",
        "ax[0,1].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[incorrect[1]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[incorrect[1]]]))\n",
        "ax[1,0].imshow(x_test[incorrect[2]].reshape(28,28), cmap='gray')\n",
        "ax[1,0].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[incorrect[2]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[incorrect[2]]]))\n",
        "ax[1,1].imshow(x_test[incorrect[3]].reshape(28,28), cmap='gray')\n",
        "ax[1,1].set_title(\"Predicted Label : \" + str(clothing[Y_pred_classes[incorrect[3]]]) + \"\\n\"+\"Actual Label : \" +\n",
        "                 str(clothing[Y_true[incorrect[3]]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bd5d173aeeb5ec0ad152d9b7c9c22ddeae1e6ef4",
        "id": "uEcK_ODqB92-"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"there_you_go_8\"></a>\n",
        "# 8) Classification Report\n",
        "The classification report visualizer displays the precision, recall, F1, and support scores for the model.\n",
        "\n",
        "* **Precision: **\n",
        "> Precision is the ability of a classiifer not to label an instance positive that is actually negative. Basically, it is defined as as the ratio of true positives to the sum of true and false positives. “For all instances classified positive, what percent was correct?”\n",
        "\n",
        "* **Recall: **\n",
        "> Recall is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.  “For all instances that were actually positive, what percent was classified correctly?”\n",
        "\n",
        "* **F1 Score: **\n",
        "> The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0 . Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation.\n",
        "\n",
        "* **Support: **\n",
        "> Support is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for stratified sampling or rebalancing."
      ]
    },
    {
      "metadata": {
        "_uuid": "205dbe13d3a85ea13f8acf550ee0969f4318c2d3",
        "trusted": false,
        "id": "IBaAwmZtB92_"
      },
      "cell_type": "code",
      "source": [
        "classes = ['T-shirt/Top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
        "print(classification_report(Y_true, Y_pred_classes, target_names = classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8ac0bef94d4dc1400ae010e3143186c934481964",
        "id": "xwPRPzyUB93A"
      },
      "cell_type": "markdown",
      "source": [
        "**Look at the Precision of the Shirts, we can see that our model predicted less than 80% of Shirts correctly out of the total images it predicted as Shirts. We did conclude the same from the confusion matrix, where we saw that a lot of T-shirts were misclassified as Shirts.**"
      ]
    },
    {
      "metadata": {
        "_uuid": "e185f6c844a119da40ca6e8b26130916275155c8",
        "collapsed": true,
        "id": "1WrNsiVpB93A"
      },
      "cell_type": "markdown",
      "source": [
        "# 9) Predicting on the Test Data\n",
        "Let's Evaluate the Models performance on the Test Data."
      ]
    },
    {
      "metadata": {
        "_uuid": "c62fa4f8ef992589aacf96be98c20c8f42bd1904",
        "trusted": false,
        "id": "FfNxgVU5B93B"
      },
      "cell_type": "code",
      "source": [
        "X = df_test\n",
        "Y = to_categorical(test.iloc[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6c51fd5e7d99074a9c3c0d3795186fb67b170904",
        "trusted": false,
        "id": "3LLagzidB93B"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X, Y)\n",
        "\n",
        "print(\"Loss: {:.4f}\".format(score[0]))\n",
        "print(\"Accuracy: {:.4f}\".format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0a7e4f0a56e6ebd7a66ce8aed9e1206c6ff6165c",
        "id": "xklftjyoB93B"
      },
      "cell_type": "markdown",
      "source": [
        "Our model predicted 94% of Test Images correctly, which indicates that the model did pretty good job in generalizing the data."
      ]
    },
    {
      "metadata": {
        "_uuid": "22f5819926ef5aae2aef87ab60d985e0c499423f",
        "collapsed": true,
        "id": "F0kb1PNMB93B"
      },
      "cell_type": "markdown",
      "source": [
        "## END  \n",
        "**Thank You...!!  :)**"
      ]
    },
    {
      "metadata": {
        "_uuid": "3856cf331c80bc0e5036dc397894ba8a0c19c6f8",
        "id": "MP7b9RGTB93C"
      },
      "cell_type": "markdown",
      "source": [
        "## Do Star/Upvote if you like it ;)"
      ]
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "a44b0df811265bb149f118bc904d7fb6a32c7fb6",
        "id": "DsS3aaXsB93C"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}